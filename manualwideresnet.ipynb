{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c7b1e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t, torch.nn as nn, torch.nn.functional as F, torch.distributions as tdist\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import random_split\n",
    "import torchvision as tv, torchvision.transforms as tr\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "#import wideresnet # from The Google Research Authors\n",
    "import json\n",
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c17b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 3e-2\n",
    "#Normalize paramerters are mean, std:  (.49, .48, .44), (.24, .24, .26)\n",
    "# I found these values were fairly common for the CIFAR10 dataset for some reason\n",
    "#perhaps they are calculated based on that specific data\n",
    "\n",
    "transform_normal = tr.Compose(\n",
    "        [tr.ToTensor(),\n",
    "         tr.Normalize((.49, .48, .44), (.24, .24, .26))\n",
    "         #tr.Normalize((.5, .5, .5), (.5, .5, .5)) #,\n",
    "         #lambda x: x + sigma * t.randn_like(x)  #keeping the transform basic for now, just normalize the tensors\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# pull the datasets, set download=True on first run\n",
    "normal_train = tv.datasets.CIFAR10(root='root', transform=transform_normal, download=False, train=True)\n",
    "normal_test = tv.datasets.CIFAR10(root='root', transform=transform_normal, download=False, train=False)\n",
    "import torch.utils.data\n",
    "train_ds, val_ds = random_split(normal_train, [45000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a43793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size sets how many images are sent to the NN model at one time\n",
    "batch_size=64\n",
    "train_ds, val_ds = random_split(normal_train, [45000, 5000])\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e16644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from some torch tutorial I can't find right now\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        #X is the batch of images, y is the vector of numeric labels for them\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            #print(y)\n",
    "            #print(pred)\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04e6e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostly from \n",
    "# https://www.analyticsvidhya.com/blog/2021/09/convolutional-neural-network-pytorch-implementation-on-cifar10-dataset/\n",
    "#baseline working neural net, approximate shape of a \"wide res net\" with some modifications to experiment with\n",
    "#Conv2d(in_channels, out_channels, kernel_size, padding) takes a batch of tensors representing an image\n",
    "# so if your batch size is 64 your input shape is [64, 3, 32, 32] for this example, 64 images, with 3 channels, \n",
    "# size 32x32 pixels\n",
    "#output size is determined by the stride and kernel size\n",
    "#MaxPool2d(2, 2) has a kernel size of 2x2, and a stride of two, so it looks at each 2x2 grid individually\n",
    "# and takes the maximum value for the output, then the result size is half the input\n",
    "class NNThree(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  #input tensors [x, 3, 32, 32]\n",
    "            nn.Softplus(), #softplus is a different non-linear activation function, similar to ReLU\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  #input [ x, 32, 32, 32]\n",
    "            nn.Softplus(),  #output [x, 64, 32, 32]\n",
    "            nn.MaxPool2d(2, 2),  #output [x, 64, 16, 16]\n",
    "            nn.BatchNorm2d(64), #, eps=1e-05, momentum=0.3, affine=True, track_running_stats=True),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1), #out [1, 128, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1), #out [1, 128, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1), # out [1, 256, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1), # out [1, 256, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "            nn.BatchNorm2d(256),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24fd79a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNThree(\n",
      "  (network): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Softplus(beta=1, threshold=20)\n",
      "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Softplus(beta=1, threshold=20)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU()\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU()\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): Flatten(start_dim=1, end_dim=-1)\n",
      "    (19): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (20): ReLU()\n",
      "    (21): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (22): ReLU()\n",
      "    (23): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# set loss function and optimizer\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "model = NNThree()\n",
    "model.to(device)\n",
    "print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#optimizer = t.optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3,weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6e84dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.299479 [    0/45000]\n",
      "loss: 1.431652 [ 6400/45000]\n",
      "loss: 1.267904 [12800/45000]\n",
      "loss: 1.147335 [19200/45000]\n",
      "loss: 0.965200 [25600/45000]\n",
      "loss: 0.944239 [32000/45000]\n",
      "loss: 1.070046 [38400/45000]\n",
      "loss: 0.854743 [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 1.322254 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.911841 [    0/45000]\n",
      "loss: 1.019013 [ 6400/45000]\n",
      "loss: 0.767046 [12800/45000]\n",
      "loss: 1.054867 [19200/45000]\n",
      "loss: 0.853269 [25600/45000]\n",
      "loss: 0.749406 [32000/45000]\n",
      "loss: 0.785524 [38400/45000]\n",
      "loss: 0.879114 [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 1.123281 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.446158 [    0/45000]\n",
      "loss: 0.763686 [ 6400/45000]\n",
      "loss: 0.549196 [12800/45000]\n",
      "loss: 0.708407 [19200/45000]\n",
      "loss: 0.793663 [25600/45000]\n",
      "loss: 0.556533 [32000/45000]\n",
      "loss: 0.650160 [38400/45000]\n",
      "loss: 0.634115 [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.856352 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.461717 [    0/45000]\n",
      "loss: 0.297720 [ 6400/45000]\n",
      "loss: 0.449933 [12800/45000]\n",
      "loss: 0.491865 [19200/45000]\n",
      "loss: 0.477042 [25600/45000]\n",
      "loss: 0.417469 [32000/45000]\n",
      "loss: 0.521112 [38400/45000]\n",
      "loss: 0.308037 [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.652719 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.272856 [    0/45000]\n",
      "loss: 0.501420 [ 6400/45000]\n",
      "loss: 0.306293 [12800/45000]\n",
      "loss: 0.352244 [19200/45000]\n",
      "loss: 0.472913 [25600/45000]\n",
      "loss: 0.389721 [32000/45000]\n",
      "loss: 0.418685 [38400/45000]\n",
      "loss: 0.422304 [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.643045 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t1 in range(epochs):\n",
    "    print(f\"Epoch {t1+1}\\n-------------------------------\")\n",
    "    train(train_dl, model, loss_fn, optimizer)\n",
    "    test(val_dl, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db764620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying different stride values per block to see effects.  need to adjust the expected output shape though\n",
    "# greater stride -> smaller result images, and probably necessary to add padding\n",
    "class NNFour(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.Softplus(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Softplus(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(64), #, eps=1e-05, momentum=0.3, affine=True, track_running_stats=True),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "            nn.BatchNorm2d(256),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3573663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNFour(\n",
      "  (network): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Softplus(beta=1, threshold=20)\n",
      "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Softplus(beta=1, threshold=20)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(3, 3), padding=(1, 1))\n",
      "    (13): ReLU()\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(3, 3), padding=(1, 1))\n",
      "    (15): ReLU()\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): Flatten(start_dim=1, end_dim=-1)\n",
      "    (19): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (20): ReLU()\n",
      "    (21): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (22): ReLU()\n",
      "    (23): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# don't run this one\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "model = NNFour()\n",
    "model.to(device)\n",
    "print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#optimizer = t.optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3,weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d09f251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (256x1x1). Calculated output size: (256x0x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-86abb64e4087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t1+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-66c2ec02df58>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-23499c614bca>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xb)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[1;32m    163\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                             self.return_indices)\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (256x1x1). Calculated output size: (256x0x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "#ignore this\n",
    "epochs = 5\n",
    "for t1 in range(epochs):\n",
    "    print(f\"Epoch {t1+1}\\n-------------------------------\")\n",
    "    train(train_dl, model, loss_fn, optimizer)\n",
    "    test(val_dl, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ae6f9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32, 32])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network1 = nn.Sequential(nn.Conv2d(3, 32, kernel_size=3, padding=1))\n",
    "#trying out the Conv2d by itself\n",
    "(Q, p) = normal_train[0]\n",
    "Q.to(device)\n",
    "# get a single image and put it into a tensor of the correct shape of a batch\n",
    "carrier = t.randn(1, 3, 32, 32)\n",
    "carrier[0] = images[0]\n",
    "step1 = network1(carrier)\n",
    "step1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5e459e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tempimg = step1[0][0].detach()\n",
    "#tempimg.requires_grad=False\n",
    "plt.imshow(tempimg)\n",
    "plt.show()\n",
    "#show one part of the result of the pass through Conv2d.  There are 32 channels now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b678b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#taken from a pytorch tutorial.  Check out the original image.\n",
    "#don't go back and shuffle the data between these steps\n",
    "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "dataiter = iter(train_dl)\n",
    "images, labels = dataiter.next()\n",
    "imshow(images[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9422790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae877ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 16, 16])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2, 2)\n",
    "#try out the MaxPool2d step alone\n",
    "pooled = pool(step1)\n",
    "pooled.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0787380a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tempimg2 = pooled[0][15].detach()\n",
    "#tempimg.requires_grad=False\n",
    "plt.imshow(tempimg2)\n",
    "plt.show()\n",
    "#show part of the pooled data.  there are still 32 channels and the images are quarter size now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1aaacdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "PATH = './manualwideresnetCIFAR10.pth'\n",
    "t.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c15c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a saved model back in\n",
    "model = NNThree()\n",
    "model.load_state_dict(t.load(PATH))\n",
    "model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
